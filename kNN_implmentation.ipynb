{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of K_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Converting Data Frame to Pytorch tensor\n",
    "\n",
    "    - load encoding csv file into data frame\n",
    "    - take only the encoded columns and convert into numpy\n",
    "    - now convert those numpy values to pytorch tensor and copy to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on Alex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/alex_encoding/encoding_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>encoded_0</th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_1014</th>\n",
       "      <th>encoded_1015</th>\n",
       "      <th>encoded_1016</th>\n",
       "      <th>encoded_1017</th>\n",
       "      <th>encoded_1018</th>\n",
       "      <th>encoded_1019</th>\n",
       "      <th>encoded_1020</th>\n",
       "      <th>encoded_1021</th>\n",
       "      <th>encoded_1022</th>\n",
       "      <th>encoded_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000075604a</td>\n",
       "      <td>6bdca6e490.jpg</td>\n",
       "      <td>0.213690</td>\n",
       "      <td>0.254143</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>0.871673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173298</td>\n",
       "      <td>2.298700</td>\n",
       "      <td>0.127594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143134</td>\n",
       "      <td>1.333617</td>\n",
       "      <td>0.320830</td>\n",
       "      <td>1.209395</td>\n",
       "      <td>1.983253</td>\n",
       "      <td>1.801040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00007bfd16</td>\n",
       "      <td>6409eab844.jpg</td>\n",
       "      <td>3.736162</td>\n",
       "      <td>6.597008</td>\n",
       "      <td>4.941602</td>\n",
       "      <td>1.239078</td>\n",
       "      <td>0.403210</td>\n",
       "      <td>0.318469</td>\n",
       "      <td>0.222777</td>\n",
       "      <td>0.782325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000095fc1d</td>\n",
       "      <td>a1374cdd98.jpg</td>\n",
       "      <td>3.113306</td>\n",
       "      <td>2.854025</td>\n",
       "      <td>2.688789</td>\n",
       "      <td>1.358068</td>\n",
       "      <td>1.585247</td>\n",
       "      <td>2.266678</td>\n",
       "      <td>0.548850</td>\n",
       "      <td>0.971478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635072</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.680662</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>1.607502</td>\n",
       "      <td>1.960970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000b1e2b5</td>\n",
       "      <td>cb1a684683.jpg</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.824535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240313</td>\n",
       "      <td>0.059274</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247056</td>\n",
       "      <td>1.347328</td>\n",
       "      <td>1.809847</td>\n",
       "      <td>0.238808</td>\n",
       "      <td>2.559675</td>\n",
       "      <td>0.465984</td>\n",
       "      <td>0.975320</td>\n",
       "      <td>1.021264</td>\n",
       "      <td>0.119180</td>\n",
       "      <td>0.146033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c79afb</td>\n",
       "      <td>2f4b4c4452.jpg</td>\n",
       "      <td>0.484349</td>\n",
       "      <td>1.256083</td>\n",
       "      <td>0.359304</td>\n",
       "      <td>1.275254</td>\n",
       "      <td>0.093606</td>\n",
       "      <td>0.042257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244099</td>\n",
       "      <td>0.451293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280742</th>\n",
       "      <td>ffff04dc41</td>\n",
       "      <td>30eb51d14c.jpg</td>\n",
       "      <td>1.013533</td>\n",
       "      <td>1.918724</td>\n",
       "      <td>1.680400</td>\n",
       "      <td>0.101543</td>\n",
       "      <td>0.133608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.744615</td>\n",
       "      <td>0.381688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183170</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>2.938093</td>\n",
       "      <td>0.254057</td>\n",
       "      <td>1.577386</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.296276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280743</th>\n",
       "      <td>ffff43701e</td>\n",
       "      <td>eda1a4e605.jpg</td>\n",
       "      <td>4.995702</td>\n",
       "      <td>2.675699</td>\n",
       "      <td>0.902978</td>\n",
       "      <td>2.184537</td>\n",
       "      <td>3.057896</td>\n",
       "      <td>1.699590</td>\n",
       "      <td>5.906440</td>\n",
       "      <td>2.120128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857434</td>\n",
       "      <td>1.365958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.801414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280744</th>\n",
       "      <td>ffffcd4444</td>\n",
       "      <td>be3b1c7122.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.423423</td>\n",
       "      <td>1.015439</td>\n",
       "      <td>1.725580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.084663</td>\n",
       "      <td>1.221924</td>\n",
       "      <td>0.427211</td>\n",
       "      <td>1.516287</td>\n",
       "      <td>2.285784</td>\n",
       "      <td>4.832259</td>\n",
       "      <td>0.810528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040364</td>\n",
       "      <td>0.509820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280745</th>\n",
       "      <td>ffffd33513</td>\n",
       "      <td>15c1a2afd4.jpg</td>\n",
       "      <td>0.502969</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189479</td>\n",
       "      <td>0.626572</td>\n",
       "      <td>1.119680</td>\n",
       "      <td>1.533680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098253</td>\n",
       "      <td>0.331980</td>\n",
       "      <td>4.437345</td>\n",
       "      <td>0.875123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103370</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280746</th>\n",
       "      <td>ffffd533d7</td>\n",
       "      <td>f2b6617941.jpg</td>\n",
       "      <td>1.431595</td>\n",
       "      <td>3.257547</td>\n",
       "      <td>1.783486</td>\n",
       "      <td>1.628023</td>\n",
       "      <td>0.386655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.301041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>0.760469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720309</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.598562</td>\n",
       "      <td>1.594499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461555</td>\n",
       "      <td>0.906193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280747 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        image_id  encoded_0  encoded_1  encoded_2  \\\n",
       "0       000075604a  6bdca6e490.jpg   0.213690   0.254143   0.135755   \n",
       "1       00007bfd16  6409eab844.jpg   3.736162   6.597008   4.941602   \n",
       "2       000095fc1d  a1374cdd98.jpg   3.113306   2.854025   2.688789   \n",
       "3       0000b1e2b5  cb1a684683.jpg   0.055429   0.000000   2.824535   \n",
       "4       0000c79afb  2f4b4c4452.jpg   0.484349   1.256083   0.359304   \n",
       "...            ...             ...        ...        ...        ...   \n",
       "280742  ffff04dc41  30eb51d14c.jpg   1.013533   1.918724   1.680400   \n",
       "280743  ffff43701e  eda1a4e605.jpg   4.995702   2.675699   0.902978   \n",
       "280744  ffffcd4444  be3b1c7122.jpg   0.000000   0.000000   0.000000   \n",
       "280745  ffffd33513  15c1a2afd4.jpg   0.502969   0.043087   0.008109   \n",
       "280746  ffffd533d7  f2b6617941.jpg   1.431595   3.257547   1.783486   \n",
       "\n",
       "        encoded_3  encoded_4  encoded_5  encoded_6  encoded_7  ...  \\\n",
       "0        0.871673   0.000000   0.173298   2.298700   0.127594  ...   \n",
       "1        1.239078   0.403210   0.318469   0.222777   0.782325  ...   \n",
       "2        1.358068   1.585247   2.266678   0.548850   0.971478  ...   \n",
       "3        0.000000   0.240313   0.059274   0.440367   0.014268  ...   \n",
       "4        1.275254   0.093606   0.042257   0.000000   0.000000  ...   \n",
       "...           ...        ...        ...        ...        ...  ...   \n",
       "280742   0.101543   0.133608   0.000000   3.744615   0.381688  ...   \n",
       "280743   2.184537   3.057896   1.699590   5.906440   2.120128  ...   \n",
       "280744   0.000000   2.423423   1.015439   1.725580   0.000000  ...   \n",
       "280745   0.000000   0.189479   0.626572   1.119680   1.533680  ...   \n",
       "280746   1.628023   0.386655   0.000000   0.016558   0.301041  ...   \n",
       "\n",
       "        encoded_1014  encoded_1015  encoded_1016  encoded_1017  encoded_1018  \\\n",
       "0           0.143134      1.333617      0.320830      1.209395      1.983253   \n",
       "1           0.500033      0.977747      0.000000      0.031324      0.000000   \n",
       "2           0.635072      0.196143      0.680662      0.336033      1.607502   \n",
       "3           1.247056      1.347328      1.809847      0.238808      2.559675   \n",
       "4           0.244099      0.451293      0.000000      0.000000      0.000000   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "280742      0.183170      0.323274      1.467262      2.938093      0.254057   \n",
       "280743      0.857434      1.365958      0.000000      0.333333      0.016225   \n",
       "280744      3.084663      1.221924      0.427211      1.516287      2.285784   \n",
       "280745      0.098253      0.331980      4.437345      0.875123      0.000000   \n",
       "280746      0.951802      0.760469      0.000000      0.720309      0.091692   \n",
       "\n",
       "        encoded_1019  encoded_1020  encoded_1021  encoded_1022  encoded_1023  \n",
       "0           1.801040      0.000000      0.000000      0.000000      0.000000  \n",
       "1           0.000000      0.033263      0.000000      0.025164      0.000000  \n",
       "2           1.960970      0.000000      0.000000      0.000000      0.005487  \n",
       "3           0.465984      0.975320      1.021264      0.119180      0.146033  \n",
       "4           0.000000      0.674627      0.000000      0.000000      0.000000  \n",
       "...              ...           ...           ...           ...           ...  \n",
       "280742      1.577386      0.024614      0.296276      0.000000      0.258263  \n",
       "280743      0.801414      0.000000      0.000000      0.000000      0.000000  \n",
       "280744      4.832259      0.810528      0.000000      0.040364      0.509820  \n",
       "280745      0.000000      0.073967      0.000000      0.103370      0.000000  \n",
       "280746      0.598562      1.594499      0.000000      0.461555      0.906193  \n",
       "\n",
       "[280747 rows x 1026 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_0</th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>encoded_8</th>\n",
       "      <th>encoded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_1014</th>\n",
       "      <th>encoded_1015</th>\n",
       "      <th>encoded_1016</th>\n",
       "      <th>encoded_1017</th>\n",
       "      <th>encoded_1018</th>\n",
       "      <th>encoded_1019</th>\n",
       "      <th>encoded_1020</th>\n",
       "      <th>encoded_1021</th>\n",
       "      <th>encoded_1022</th>\n",
       "      <th>encoded_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213690</td>\n",
       "      <td>0.254143</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>0.871673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173298</td>\n",
       "      <td>2.298700</td>\n",
       "      <td>0.127594</td>\n",
       "      <td>1.123788</td>\n",
       "      <td>2.330151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143134</td>\n",
       "      <td>1.333617</td>\n",
       "      <td>0.320830</td>\n",
       "      <td>1.209395</td>\n",
       "      <td>1.983253</td>\n",
       "      <td>1.801040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.736162</td>\n",
       "      <td>6.597008</td>\n",
       "      <td>4.941602</td>\n",
       "      <td>1.239078</td>\n",
       "      <td>0.403210</td>\n",
       "      <td>0.318469</td>\n",
       "      <td>0.222777</td>\n",
       "      <td>0.782325</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.113306</td>\n",
       "      <td>2.854025</td>\n",
       "      <td>2.688789</td>\n",
       "      <td>1.358068</td>\n",
       "      <td>1.585247</td>\n",
       "      <td>2.266678</td>\n",
       "      <td>0.548850</td>\n",
       "      <td>0.971478</td>\n",
       "      <td>0.694944</td>\n",
       "      <td>1.597406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635072</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.680662</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>1.607502</td>\n",
       "      <td>1.960970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.824535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240313</td>\n",
       "      <td>0.059274</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>2.730922</td>\n",
       "      <td>2.545960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247056</td>\n",
       "      <td>1.347328</td>\n",
       "      <td>1.809847</td>\n",
       "      <td>0.238808</td>\n",
       "      <td>2.559675</td>\n",
       "      <td>0.465984</td>\n",
       "      <td>0.975320</td>\n",
       "      <td>1.021264</td>\n",
       "      <td>0.119180</td>\n",
       "      <td>0.146033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.484349</td>\n",
       "      <td>1.256083</td>\n",
       "      <td>0.359304</td>\n",
       "      <td>1.275254</td>\n",
       "      <td>0.093606</td>\n",
       "      <td>0.042257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.505058</td>\n",
       "      <td>1.778495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244099</td>\n",
       "      <td>0.451293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280742</th>\n",
       "      <td>1.013533</td>\n",
       "      <td>1.918724</td>\n",
       "      <td>1.680400</td>\n",
       "      <td>0.101543</td>\n",
       "      <td>0.133608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.744615</td>\n",
       "      <td>0.381688</td>\n",
       "      <td>3.143268</td>\n",
       "      <td>0.515954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183170</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>2.938093</td>\n",
       "      <td>0.254057</td>\n",
       "      <td>1.577386</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.296276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280743</th>\n",
       "      <td>4.995702</td>\n",
       "      <td>2.675699</td>\n",
       "      <td>0.902978</td>\n",
       "      <td>2.184537</td>\n",
       "      <td>3.057896</td>\n",
       "      <td>1.699590</td>\n",
       "      <td>5.906440</td>\n",
       "      <td>2.120128</td>\n",
       "      <td>0.473211</td>\n",
       "      <td>0.476595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857434</td>\n",
       "      <td>1.365958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.801414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280744</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.423423</td>\n",
       "      <td>1.015439</td>\n",
       "      <td>1.725580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.052260</td>\n",
       "      <td>0.360695</td>\n",
       "      <td>...</td>\n",
       "      <td>3.084663</td>\n",
       "      <td>1.221924</td>\n",
       "      <td>0.427211</td>\n",
       "      <td>1.516287</td>\n",
       "      <td>2.285784</td>\n",
       "      <td>4.832259</td>\n",
       "      <td>0.810528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040364</td>\n",
       "      <td>0.509820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280745</th>\n",
       "      <td>0.502969</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189479</td>\n",
       "      <td>0.626572</td>\n",
       "      <td>1.119680</td>\n",
       "      <td>1.533680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098253</td>\n",
       "      <td>0.331980</td>\n",
       "      <td>4.437345</td>\n",
       "      <td>0.875123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103370</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280746</th>\n",
       "      <td>1.431595</td>\n",
       "      <td>3.257547</td>\n",
       "      <td>1.783486</td>\n",
       "      <td>1.628023</td>\n",
       "      <td>0.386655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.301041</td>\n",
       "      <td>1.117240</td>\n",
       "      <td>1.416304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>0.760469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720309</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.598562</td>\n",
       "      <td>1.594499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461555</td>\n",
       "      <td>0.906193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280747 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        encoded_0  encoded_1  encoded_2  encoded_3  encoded_4  encoded_5  \\\n",
       "0        0.213690   0.254143   0.135755   0.871673   0.000000   0.173298   \n",
       "1        3.736162   6.597008   4.941602   1.239078   0.403210   0.318469   \n",
       "2        3.113306   2.854025   2.688789   1.358068   1.585247   2.266678   \n",
       "3        0.055429   0.000000   2.824535   0.000000   0.240313   0.059274   \n",
       "4        0.484349   1.256083   0.359304   1.275254   0.093606   0.042257   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "280742   1.013533   1.918724   1.680400   0.101543   0.133608   0.000000   \n",
       "280743   4.995702   2.675699   0.902978   2.184537   3.057896   1.699590   \n",
       "280744   0.000000   0.000000   0.000000   0.000000   2.423423   1.015439   \n",
       "280745   0.502969   0.043087   0.008109   0.000000   0.189479   0.626572   \n",
       "280746   1.431595   3.257547   1.783486   1.628023   0.386655   0.000000   \n",
       "\n",
       "        encoded_6  encoded_7  encoded_8  encoded_9  ...  encoded_1014  \\\n",
       "0        2.298700   0.127594   1.123788   2.330151  ...      0.143134   \n",
       "1        0.222777   0.782325   0.016133   0.016133  ...      0.500033   \n",
       "2        0.548850   0.971478   0.694944   1.597406  ...      0.635072   \n",
       "3        0.440367   0.014268   2.730922   2.545960  ...      1.247056   \n",
       "4        0.000000   0.000000   1.505058   1.778495  ...      0.244099   \n",
       "...           ...        ...        ...        ...  ...           ...   \n",
       "280742   3.744615   0.381688   3.143268   0.515954  ...      0.183170   \n",
       "280743   5.906440   2.120128   0.473211   0.476595  ...      0.857434   \n",
       "280744   1.725580   0.000000   1.052260   0.360695  ...      3.084663   \n",
       "280745   1.119680   1.533680   0.000000   0.000000  ...      0.098253   \n",
       "280746   0.016558   0.301041   1.117240   1.416304  ...      0.951802   \n",
       "\n",
       "        encoded_1015  encoded_1016  encoded_1017  encoded_1018  encoded_1019  \\\n",
       "0           1.333617      0.320830      1.209395      1.983253      1.801040   \n",
       "1           0.977747      0.000000      0.031324      0.000000      0.000000   \n",
       "2           0.196143      0.680662      0.336033      1.607502      1.960970   \n",
       "3           1.347328      1.809847      0.238808      2.559675      0.465984   \n",
       "4           0.451293      0.000000      0.000000      0.000000      0.000000   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "280742      0.323274      1.467262      2.938093      0.254057      1.577386   \n",
       "280743      1.365958      0.000000      0.333333      0.016225      0.801414   \n",
       "280744      1.221924      0.427211      1.516287      2.285784      4.832259   \n",
       "280745      0.331980      4.437345      0.875123      0.000000      0.000000   \n",
       "280746      0.760469      0.000000      0.720309      0.091692      0.598562   \n",
       "\n",
       "        encoded_1020  encoded_1021  encoded_1022  encoded_1023  \n",
       "0           0.000000      0.000000      0.000000      0.000000  \n",
       "1           0.033263      0.000000      0.025164      0.000000  \n",
       "2           0.000000      0.000000      0.000000      0.005487  \n",
       "3           0.975320      1.021264      0.119180      0.146033  \n",
       "4           0.674627      0.000000      0.000000      0.000000  \n",
       "...              ...           ...           ...           ...  \n",
       "280742      0.024614      0.296276      0.000000      0.258263  \n",
       "280743      0.000000      0.000000      0.000000      0.000000  \n",
       "280744      0.810528      0.000000      0.040364      0.509820  \n",
       "280745      0.073967      0.000000      0.103370      0.000000  \n",
       "280746      1.594499      0.000000      0.461555      0.906193  \n",
       "\n",
       "[280747 rows x 1024 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.13690177e-01, 2.54143387e-01, 1.35755137e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.73616195e+00, 6.59700775e+00, 4.94160175e+00, ...,\n",
       "        0.00000000e+00, 2.51641739e-02, 0.00000000e+00],\n",
       "       [3.11330581e+00, 2.85402465e+00, 2.68878865e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.48664667e-03],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 4.03641127e-02, 5.09819686e-01],\n",
       "       [5.02969325e-01, 4.30869497e-02, 8.10931623e-03, ...,\n",
       "        0.00000000e+00, 1.03370100e-01, 0.00000000e+00],\n",
       "       [1.43159485e+00, 3.25754666e+00, 1.78348589e+00, ...,\n",
       "        0.00000000e+00, 4.61554855e-01, 9.06193316e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1369e-01, 2.5414e-01, 1.3576e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [3.7362e+00, 6.5970e+00, 4.9416e+00,  ..., 0.0000e+00, 2.5164e-02,\n",
       "         0.0000e+00],\n",
       "        [3.1133e+00, 2.8540e+00, 2.6888e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         5.4866e-03],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.0364e-02,\n",
       "         5.0982e-01],\n",
       "        [5.0297e-01, 4.3087e-02, 8.1093e-03,  ..., 0.0000e+00, 1.0337e-01,\n",
       "         0.0000e+00],\n",
       "        [1.4316e+00, 3.2575e+00, 1.7835e+00,  ..., 0.0000e+00, 4.6155e-01,\n",
       "         9.0619e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([280747, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Obtaining the new encoding for test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(progress = True, pretrained = True)\n",
    "modi_alexnet = torch.nn.Sequential(*(list(alexnet.children())[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500----------completed!\n",
      "1000----------completed!\n",
      "1500----------completed!\n",
      "2000----------completed!\n",
      "2500----------completed!\n",
      "3000----------completed!\n",
      "3500----------completed!\n",
      "4000----------completed!\n",
      "4500----------completed!\n",
      "5000----------completed!\n",
      "5500----------completed!\n",
      "6000----------completed!\n",
      "6500----------completed!\n",
      "7000----------completed!\n",
      "7500----------completed!\n",
      "8000----------completed!\n",
      "8500----------completed!\n",
      "9000----------completed!\n",
      "9500----------completed!\n",
      "10000----------completed!\n",
      "10500----------completed!\n",
      "11000----------completed!\n",
      "11500----------completed!\n",
      "12000----------completed!\n",
      "12500----------completed!\n",
      "13000----------completed!\n",
      "13500----------completed!\n",
      "14000----------completed!\n",
      "total time taken = 00:36:05.88\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_alexnet.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_alexnet(input_batch)\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=(2,2))\n",
    "    output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,1024))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 500 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/alexnet/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/alexnet/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([35.6281, 36.8806, 37.2691], device='cuda:0'),\n",
       " tensor([0.7538, 0.7388, 0.7331], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(count)\n",
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10730.6455, 10516.8770, 10436.0986], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image = Image.open('data/test/000ad38272_10b735780a.jpg')\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "# input_tensor = preprocess(input_image)\n",
    "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# # move the input and model to GPU for speed if available\n",
    "# if torch.cuda.is_available():\n",
    "#     input_batch = input_batch.to('cuda')\n",
    "#     modi_alexnet.to('cuda')\n",
    "    \n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = modi_alexnet(input_batch)\n",
    "# # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "# avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=(2,2))\n",
    "# output = avg_pool(output)\n",
    "# output = output.flatten().reshape((1,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Implementing K NN based on distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN dist: tensor([35.4068, 35.7184, 35.9263], device='cuda:0'), index: tensor([259517, 222737,  57071], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "# knn = dist.topk(3, largest=False)\n",
    "\n",
    "# print('kNN dist: {}, index: {}'.format(knn.values, knn.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259517</th>\n",
       "      <td>ecb0dfbe5b</td>\n",
       "      <td>2c4207316e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222737</th>\n",
       "      <td>cae6a1b7b3</td>\n",
       "      <td>af8611d549.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57071</th>\n",
       "      <td>3427c61c50</td>\n",
       "      <td>1b350340d7.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        image_id\n",
       "259517  ecb0dfbe5b  2c4207316e.jpg\n",
       "222737  cae6a1b7b3  af8611d549.jpg\n",
       "57071   3427c61c50  1b350340d7.jpg"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top3 = knn.indices.to('cpu').numpy()\n",
    "# df[df.columns[0:2]].iloc[top3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity: tensor([0.7463, 0.7473, 0.7493], device='cuda:0'), index: tensor([167348, 191111, 162980], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "# cso = cosine_similarity_output.topk(3, largest = False)\n",
    "# print('cosine similarity: {}, index: {}'.format(cso.values, cso.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167348</th>\n",
       "      <td>9897ed7e4f</td>\n",
       "      <td>a0b52d4e51.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191111</th>\n",
       "      <td>ae20ee73e8</td>\n",
       "      <td>43a6d9b40e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162980</th>\n",
       "      <td>94afd954cc</td>\n",
       "      <td>bbd3e7c647.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        image_id\n",
       "167348  9897ed7e4f  a0b52d4e51.jpg\n",
       "191111  ae20ee73e8  43a6d9b40e.jpg\n",
       "162980  94afd954cc  bbd3e7c647.jpg"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ctop3 = cso.indices.to('cpu').numpy()\n",
    "# df[df.columns[0:2]].iloc[ctop3.numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/densenet_encoding/encoding_file.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet161 = models.densenet161(pretrained=True, progress=True)\n",
    "modi_densenet = torch.nn.Sequential(*(list(densenet161.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500----------completed!\n",
      "1000----------completed!\n",
      "1500----------completed!\n",
      "2000----------completed!\n",
      "2500----------completed!\n",
      "3000----------completed!\n",
      "3500----------completed!\n",
      "4000----------completed!\n",
      "4500----------completed!\n",
      "5000----------completed!\n",
      "5500----------completed!\n",
      "6000----------completed!\n",
      "6500----------completed!\n",
      "7000----------completed!\n",
      "7500----------completed!\n",
      "8000----------completed!\n",
      "8500----------completed!\n",
      "9000----------completed!\n",
      "9500----------completed!\n",
      "10000----------completed!\n",
      "10500----------completed!\n",
      "11000----------completed!\n",
      "11500----------completed!\n",
      "12000----------completed!\n",
      "12500----------completed!\n",
      "13000----------completed!\n",
      "13500----------completed!\n",
      "14000----------completed!\n",
      "total time taken = 00:46:33.01\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_densenet.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_densenet(input_batch)\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "    output = avg_pool(output)\n",
    "    output = output.reshape((1,1,2208))\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool1d(1000)\n",
    "    output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,1000))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-3)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 500 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/densenet/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/densenet/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.9626e-07, 8.1010e-07, 8.1365e-07], device='cuda:0'),\n",
       " tensor([1.0000, 1.0000, 1.0000], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([14236.0010, 14236.0010, 14236.0010], device='cuda:0'), 14236)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_loss, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/googlenet_encoding/encoding_file.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleNet = models.googlenet(pretrained=True, progress=True)\n",
    "modi_googleNet = torch.nn.Sequential(*(list(googleNet.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500----------completed!\n",
      "1000----------completed!\n",
      "1500----------completed!\n",
      "2000----------completed!\n",
      "2500----------completed!\n",
      "3000----------completed!\n",
      "3500----------completed!\n",
      "4000----------completed!\n",
      "4500----------completed!\n",
      "5000----------completed!\n",
      "5500----------completed!\n",
      "6000----------completed!\n",
      "6500----------completed!\n",
      "7000----------completed!\n",
      "7500----------completed!\n",
      "8000----------completed!\n",
      "8500----------completed!\n",
      "9000----------completed!\n",
      "9500----------completed!\n",
      "10000----------completed!\n",
      "10500----------completed!\n",
      "11000----------completed!\n",
      "11500----------completed!\n",
      "12000----------completed!\n",
      "12500----------completed!\n",
      "13000----------completed!\n",
      "13500----------completed!\n",
      "14000----------completed!\n",
      "total time taken = 00:38:04.81\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_googleNet.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_googleNet(input_batch)\n",
    "    output = output.flatten().reshape((1,1024))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 500 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/googlenet/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/googlenet/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.8559, 7.8938, 7.9132], device='cuda:0'),\n",
       " tensor([0.8374, 0.8357, 0.8349], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/resnet_encoding/encoding_file.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152 = models.resnet152(pretrained=True, progress=True)\n",
    "modi_resnet = torch.nn.Sequential(*(list(resnet152.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500----------completed!\n",
      "1000----------completed!\n",
      "1500----------completed!\n",
      "2000----------completed!\n",
      "2500----------completed!\n",
      "3000----------completed!\n",
      "3500----------completed!\n",
      "4000----------completed!\n",
      "4500----------completed!\n",
      "5000----------completed!\n",
      "5500----------completed!\n",
      "6000----------completed!\n",
      "6500----------completed!\n",
      "7000----------completed!\n",
      "7500----------completed!\n",
      "8000----------completed!\n",
      "8500----------completed!\n",
      "9000----------completed!\n",
      "9500----------completed!\n",
      "10000----------completed!\n",
      "10500----------completed!\n",
      "11000----------completed!\n",
      "11500----------completed!\n",
      "12000----------completed!\n",
      "12500----------completed!\n",
      "13000----------completed!\n",
      "13500----------completed!\n",
      "14000----------completed!\n",
      "total time taken = 00:46:21.41\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_resnet.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_resnet(input_batch)\n",
    "    output = output.reshape((1,1,2048))\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool1d(output_size=(1000))\n",
    "    output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,1000))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 500 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnet/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnet/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7635, 0.7755, 0.7779], device='cuda:0'),\n",
       " tensor([0.9988, 0.9988, 0.9988], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on ResNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/resnext_encoding/encoding_file.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\balag/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.6.0', 'resnext101_32x8d', pretrained=True)\n",
    "modi_resnext = torch.nn.Sequential(*(list(resnext.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100----------completed!\n",
      "200----------completed!\n",
      "300----------completed!\n",
      "400----------completed!\n",
      "500----------completed!\n",
      "600----------completed!\n",
      "700----------completed!\n",
      "800----------completed!\n",
      "900----------completed!\n",
      "1000----------completed!\n",
      "1100----------completed!\n",
      "1200----------completed!\n",
      "1300----------completed!\n",
      "1400----------completed!\n",
      "1500----------completed!\n",
      "1600----------completed!\n",
      "1700----------completed!\n",
      "1800----------completed!\n",
      "1900----------completed!\n",
      "2000----------completed!\n",
      "2100----------completed!\n",
      "2200----------completed!\n",
      "2300----------completed!\n",
      "2400----------completed!\n",
      "2500----------completed!\n",
      "2600----------completed!\n",
      "2700----------completed!\n",
      "2800----------completed!\n",
      "2900----------completed!\n",
      "3000----------completed!\n",
      "3100----------completed!\n",
      "3200----------completed!\n",
      "3300----------completed!\n",
      "3400----------completed!\n",
      "3500----------completed!\n",
      "3600----------completed!\n",
      "3700----------completed!\n",
      "3800----------completed!\n",
      "3900----------completed!\n",
      "4000----------completed!\n",
      "4100----------completed!\n",
      "4200----------completed!\n",
      "4300----------completed!\n",
      "4400----------completed!\n",
      "4500----------completed!\n",
      "4600----------completed!\n",
      "4700----------completed!\n",
      "4800----------completed!\n",
      "4900----------completed!\n",
      "5000----------completed!\n",
      "5100----------completed!\n",
      "5200----------completed!\n",
      "5300----------completed!\n",
      "5400----------completed!\n",
      "5500----------completed!\n",
      "5600----------completed!\n",
      "5700----------completed!\n",
      "5800----------completed!\n",
      "5900----------completed!\n",
      "6000----------completed!\n",
      "6100----------completed!\n",
      "6200----------completed!\n",
      "6300----------completed!\n",
      "6400----------completed!\n",
      "6500----------completed!\n",
      "6600----------completed!\n",
      "6700----------completed!\n",
      "6800----------completed!\n",
      "6900----------completed!\n",
      "7000----------completed!\n",
      "7100----------completed!\n",
      "7200----------completed!\n",
      "7300----------completed!\n",
      "7400----------completed!\n",
      "7500----------completed!\n",
      "7600----------completed!\n",
      "7700----------completed!\n",
      "7800----------completed!\n",
      "7900----------completed!\n",
      "8000----------completed!\n",
      "8100----------completed!\n",
      "8200----------completed!\n",
      "8300----------completed!\n",
      "8400----------completed!\n",
      "8500----------completed!\n",
      "8600----------completed!\n",
      "8700----------completed!\n",
      "8800----------completed!\n",
      "8900----------completed!\n",
      "9000----------completed!\n",
      "9100----------completed!\n",
      "9200----------completed!\n",
      "9300----------completed!\n",
      "9400----------completed!\n",
      "9500----------completed!\n",
      "9600----------completed!\n",
      "9700----------completed!\n",
      "9800----------completed!\n",
      "9900----------completed!\n",
      "10000----------completed!\n",
      "10100----------completed!\n",
      "10200----------completed!\n",
      "10300----------completed!\n",
      "10400----------completed!\n",
      "10500----------completed!\n",
      "10600----------completed!\n",
      "10700----------completed!\n",
      "10800----------completed!\n",
      "10900----------completed!\n",
      "11000----------completed!\n",
      "11100----------completed!\n",
      "11200----------completed!\n",
      "11300----------completed!\n",
      "11400----------completed!\n",
      "11500----------completed!\n",
      "11600----------completed!\n",
      "11700----------completed!\n",
      "11800----------completed!\n",
      "11900----------completed!\n",
      "12000----------completed!\n",
      "12100----------completed!\n",
      "12200----------completed!\n",
      "12300----------completed!\n",
      "12400----------completed!\n",
      "12500----------completed!\n",
      "12600----------completed!\n",
      "12700----------completed!\n",
      "12800----------completed!\n",
      "12900----------completed!\n",
      "13000----------completed!\n",
      "13100----------completed!\n",
      "13200----------completed!\n",
      "13300----------completed!\n",
      "13400----------completed!\n",
      "13500----------completed!\n",
      "13600----------completed!\n",
      "13700----------completed!\n",
      "13800----------completed!\n",
      "13900----------completed!\n",
      "14000----------completed!\n",
      "14100----------completed!\n",
      "14200----------completed!\n",
      "total time taken = 00:52:31.15\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_resnext.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_resnext(input_batch)\n",
    "    output = output.reshape((1,1,2048))\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool1d(output_size=(1000))\n",
    "    output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,1000))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 100 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnext/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnext/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7643, 0.7780, 0.7813], device='cuda:0'),\n",
       " tensor([0.9986, 0.9986, 0.9986], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/vgg_encoding/encoding_file.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float().to(device)\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = models.vgg19_bn(pretrained=True, progress=True)\n",
    "modi_vgg = torch.nn.Sequential(*(list(vgg19.children())[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500----------completed!\n",
      "1000----------completed!\n",
      "1500----------completed!\n",
      "2000----------completed!\n",
      "2500----------completed!\n",
      "3000----------completed!\n",
      "3500----------completed!\n",
      "4000----------completed!\n",
      "4500----------completed!\n",
      "5000----------completed!\n",
      "5500----------completed!\n",
      "6000----------completed!\n",
      "6500----------completed!\n",
      "7000----------completed!\n",
      "7500----------completed!\n",
      "8000----------completed!\n",
      "8500----------completed!\n",
      "9000----------completed!\n",
      "9500----------completed!\n",
      "10000----------completed!\n",
      "10500----------completed!\n",
      "11000----------completed!\n",
      "11500----------completed!\n",
      "12000----------completed!\n",
      "12500----------completed!\n",
      "13000----------completed!\n",
      "13500----------completed!\n",
      "14000----------completed!\n",
      "total time taken = 00:40:09.28\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3).to('cuda')\n",
    "similarity_loss = torch.zeros(3).to('cuda')\n",
    "\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        modi_vgg.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_vgg(input_batch)\n",
    "    avg_pool = torch.nn.AdaptiveAvgPool2d((2,1))\n",
    "    output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,1024))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.to('cpu').numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.to('cpu').numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 500 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/vgg/distance_knn.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/vgg/similarity_knn.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.1642, 3.2286, 3.2448], device='cuda:0'),\n",
       " tensor([0.9034, 0.9004, 0.8995], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/resnext_encoding/encoding_file_1.csv')\n",
    "numpy_data = df[df.columns[2:]].to_numpy(dtype=np.float64)\n",
    "tensor_data = torch.from_numpy(numpy_data).float()\n",
    "del(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\balag/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "resnext = torch.hub.load('pytorch/vision:v0.6.0', 'resnext101_32x8d', pretrained=True)\n",
    "modi_resnext = torch.nn.Sequential(*(list(resnext.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100----------completed!\n",
      "200----------completed!\n",
      "300----------completed!\n",
      "400----------completed!\n",
      "500----------completed!\n",
      "600----------completed!\n",
      "700----------completed!\n",
      "800----------completed!\n",
      "900----------completed!\n",
      "1000----------completed!\n",
      "1100----------completed!\n",
      "1200----------completed!\n",
      "1300----------completed!\n",
      "1400----------completed!\n",
      "1500----------completed!\n",
      "1600----------completed!\n",
      "1700----------completed!\n",
      "1800----------completed!\n",
      "1900----------completed!\n",
      "2000----------completed!\n",
      "2100----------completed!\n",
      "2200----------completed!\n",
      "2300----------completed!\n",
      "2400----------completed!\n",
      "2500----------completed!\n",
      "2600----------completed!\n",
      "2700----------completed!\n",
      "2800----------completed!\n",
      "2900----------completed!\n",
      "3000----------completed!\n",
      "3100----------completed!\n",
      "3200----------completed!\n",
      "3300----------completed!\n",
      "3400----------completed!\n",
      "3500----------completed!\n",
      "3600----------completed!\n",
      "3700----------completed!\n",
      "3800----------completed!\n",
      "3900----------completed!\n",
      "4000----------completed!\n",
      "4100----------completed!\n",
      "4200----------completed!\n",
      "4300----------completed!\n",
      "4400----------completed!\n",
      "4500----------completed!\n",
      "4600----------completed!\n",
      "4700----------completed!\n",
      "4800----------completed!\n",
      "4900----------completed!\n",
      "5000----------completed!\n",
      "5100----------completed!\n",
      "5200----------completed!\n",
      "5300----------completed!\n",
      "5400----------completed!\n",
      "5500----------completed!\n",
      "5600----------completed!\n",
      "5700----------completed!\n",
      "5800----------completed!\n",
      "5900----------completed!\n",
      "6000----------completed!\n",
      "6100----------completed!\n",
      "6200----------completed!\n",
      "6300----------completed!\n",
      "6400----------completed!\n",
      "6500----------completed!\n",
      "6600----------completed!\n",
      "6700----------completed!\n",
      "6800----------completed!\n",
      "6900----------completed!\n",
      "7000----------completed!\n",
      "7100----------completed!\n",
      "7200----------completed!\n",
      "7300----------completed!\n",
      "7400----------completed!\n",
      "7500----------completed!\n",
      "7600----------completed!\n",
      "7700----------completed!\n",
      "7800----------completed!\n",
      "7900----------completed!\n",
      "8000----------completed!\n",
      "8100----------completed!\n",
      "8200----------completed!\n",
      "8300----------completed!\n",
      "8400----------completed!\n",
      "8500----------completed!\n",
      "8600----------completed!\n",
      "8700----------completed!\n",
      "8800----------completed!\n",
      "8900----------completed!\n",
      "9000----------completed!\n",
      "9100----------completed!\n",
      "9200----------completed!\n",
      "9300----------completed!\n",
      "9400----------completed!\n",
      "9500----------completed!\n",
      "9600----------completed!\n",
      "9700----------completed!\n",
      "9800----------completed!\n",
      "9900----------completed!\n",
      "10000----------completed!\n",
      "10100----------completed!\n",
      "10200----------completed!\n",
      "10300----------completed!\n",
      "10400----------completed!\n",
      "10500----------completed!\n",
      "10600----------completed!\n",
      "10700----------completed!\n",
      "10800----------completed!\n",
      "10900----------completed!\n",
      "11000----------completed!\n",
      "11100----------completed!\n",
      "11200----------completed!\n",
      "11300----------completed!\n",
      "11400----------completed!\n",
      "11500----------completed!\n",
      "11600----------completed!\n",
      "11700----------completed!\n",
      "11800----------completed!\n",
      "11900----------completed!\n",
      "12000----------completed!\n",
      "12100----------completed!\n",
      "12200----------completed!\n",
      "12300----------completed!\n",
      "12400----------completed!\n",
      "12500----------completed!\n",
      "12600----------completed!\n",
      "12700----------completed!\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "distance_loss = torch.zeros(3)\n",
    "similarity_loss = torch.zeros(3)\n",
    "\n",
    "for image in os.listdir('data/test'):\n",
    "    input_image = Image.open('data/test/'+image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "#     if torch.cuda.is_available():\n",
    "#         input_batch = input_batch.to('cuda')\n",
    "#         modi_resnext.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = modi_resnext(input_batch)\n",
    "#     output = output.reshape((1,1,2048))\n",
    "#     avg_pool = torch.nn.AdaptiveAvgPool1d(output_size=(1000))\n",
    "#     output = avg_pool(output)\n",
    "    output = output.flatten().reshape((1,2048))\n",
    "    \n",
    "    #implementing KNN using distance metric\n",
    "    dist = torch.norm(tensor_data - output, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    top3 = knn.indices.numpy()\n",
    "    data1.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    distance_loss = distance_loss + knn.values\n",
    "    \n",
    "    #implementing KNN using cosine metric\n",
    "    cosine_similarity_output = torch.cosine_similarity(tensor_data, output, dim=1, eps=1e-6)\n",
    "    cso = cosine_similarity_output.topk(3, largest = True)\n",
    "    top3 = cso.indices.numpy()\n",
    "    data2.append([image[0:10], image[11:],\n",
    "                  df['id'].iloc[top3[0]], df['image_id'].iloc[top3[0]], \n",
    "                  df['id'].iloc[top3[1]], df['image_id'].iloc[top3[1]], \n",
    "                  df['id'].iloc[top3[2]], df['image_id'].iloc[top3[2]]])\n",
    "    \n",
    "    similarity_loss = similarity_loss + cso.values\n",
    "    \n",
    "    count = count + 1\n",
    "    if(count % 100 == 0):\n",
    "        print(str(count)+ '----------completed!')\n",
    "\n",
    "df = pd.DataFrame(data1, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnext/distance_knn2.csv',index = False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2, columns = ['test_id', 'test_image_id',\n",
    "                                    'top1_id', 'top1_image_id',\n",
    "                                    'top2_id', 'top2_image_id',\n",
    "                                    'top3_id', 'top3_image_id',])\n",
    "df.to_csv('data/output/resnext/similarity_knn2.csv',index = False)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"total time taken = {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.1642, 3.2286, 3.2448], device='cuda:0'),\n",
       " tensor([0.9034, 0.9004, 0.8995], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_loss = distance_loss/count\n",
    "avg_similarity_loss = similarity_loss/count\n",
    "avg_dist_loss, avg_similarity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
